{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zCu72vDHGMHo"
   },
   "source": [
    "## **| 앙상블 학습과 랜덤 포레스트 연습 문제**\n",
    "___\n",
    "- 출처 : 핸즈온 머신러닝 Ch07 앙상블 학습과 랜덤 포레스트 연습문제 2, 7, 8, 9번\n",
    "- 이론적 지식을 묻는 문제의 경우 텍스트 셀을 추가하여 정답을 적어주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "hQLO-M61qSVA"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ifUj-jvi5NE"
   },
   "source": [
    "### **1. 직접 투표와 간접 투표 분류기 사이의 차이점은 무엇일까요?**\n",
    "\n",
    "직접 투표 분류기는 횟수를 중요시하여, 가장 많은 투표를 얻은 클래스를 선택. (다수결)\n",
    "\n",
    "간접 투표 분류기는 각 클래스의 평균적인 확률 추정값을 계산해서 가장 높은 확률을 가진 클래스를 고름. 이 방법은 신뢰가 높은 투표에 더 가중치를 주고 종종 더 나은 성능을 낸다. 하지만 앙상블에 있는 모든 분류기가 클래스 확률을 추정할 수 있어야 사용 가능!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JK-WcK3ujU0E"
   },
   "source": [
    "### **2. 그레디언트 부스팅 앙상블이 훈련 데이터에 과대 적합되었다면 학습률을 어떻게 해야 할까요?**\n",
    "___\n",
    "\n",
    "학습률을 감소시켜야한다 ( 예측기 수가 너무 많으면 ) 알맞은 개수를 찾기 위해 조기 종료 기법을 사용할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j3g-_Dq9GiuT"
   },
   "source": [
    "### **3. [실습] 다음 지시에 따라 투표 기반 분류 모델을 만들어 보세요**\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7aLghZCVj34L"
   },
   "source": [
    "#### **STEP 1. MNIST 데이터를 불러들이고, 훈련, 검증, 테스트 데이터로 나누세요.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "188lZyYEGJZ7"
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "mnist = fetch_openml('mnist_784', version=1, as_frame = False)\n",
    "X, y = mnist[\"data\"], mnist[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "lXF4M2MdIpKa"
   },
   "outputs": [],
   "source": [
    "# train/valid/test dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mHOTxVK3kjnM"
   },
   "source": [
    "####  **STEP 2. 랜덤 포레스트 분류기, 엑스트라 트리 분류기, SVM 분류기, MLP 분류기를 훈련시키세요.**\n",
    "- 모델 파라미터는 `n_estimators=100`, `random_state=42`로 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "udX8yKD4k9DE"
   },
   "outputs": [],
   "source": [
    "# import package\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "iEG8FFJ1lBw4"
   },
   "outputs": [],
   "source": [
    "# model fitting\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=10,random_state=0)\n",
    "ext_clf = ExtraTreesClassifier(n_estimators=10, random_state=0)\n",
    "svm_clf = LinearSVC(max_iter=10000,random_state=0)\n",
    "mlp_clf = MLPClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lB4OagE2lglK"
   },
   "source": [
    "####  **STEP 3-1. 앞에서 훈련시킨 각 모델을 직접 투표 방법을 사용해 앙상블로 연결하고 훈련시킨 후, `score()`메서드를 이용하여 검증 데이터셋에서의 성능을 평가해보세요.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "6gGlXpJrlqzz"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "LTnt0h4Hmitr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 : RandomForestClassifier(n_estimators=10, random_state=0)\n",
      "훈련 : ExtraTreesClassifier(n_estimators=10, random_state=0)\n",
      "훈련 : LinearSVC(max_iter=10000, random_state=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MYCOM\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 : MLPClassifier(random_state=0)\n"
     ]
    }
   ],
   "source": [
    "# model fitting\n",
    "models = [rnd_clf,ext_clf,svm_clf,mlp_clf]\n",
    "\n",
    "for model in models:\n",
    "    print(\"훈련 :\",model)\n",
    "    model.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "6M8p66FHmt0U"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 : 0.9429047619047619\n",
      "정확도 : 0.9484761904761905\n",
      "정확도 : 0.8571904761904762\n",
      "정확도 : 0.9654761904761905\n"
     ]
    }
   ],
   "source": [
    "# model test\n",
    "\n",
    "for model in models:\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"정확도 :\",accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tgmsaye3oLYQ"
   },
   "source": [
    "####  **STEP 3-2. 검증 데이터셋에서 각 분류 모델의 성능을 `score()` 메서드를 이용하여 확인해보고, 가장 성능이 낮은 모델을 제거하여 그 결과를 비교해보세요.**\n",
    "- Hint : 가장 성능이 낮은 모델을 제거할 때 `del`를 활용해보세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Ykw6-_4rV9S"
   },
   "outputs": [],
   "source": [
    "# 각 분류 모델 학습\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "named_models = [\n",
    "    (\"RandomForest\" , rnd_clf),\n",
    "    (\"ExtraTree\" , ext_clf),\n",
    "    (\"LinearSVM\" , svm_clf),\n",
    "    (\"MLP\" , mlp_clf),\n",
    "]\n",
    "voting_clf = VotingClassifier(named_models)\n",
    "voting_clf.fit(X_train,y_train)\n",
    "voting_clf.set_params(LinearSVM=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GN-HIeWhosGs"
   },
   "source": [
    "- Q. 어떤 모델의 성능이 가장 낮나요?\n",
    "- A.SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "shHFXdWcoqf6"
   },
   "outputs": [],
   "source": [
    "# 가장 성능이 낮은 모델 제거\n",
    "\n",
    "voting_clf.set_params(LinearSVM=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BMTkSkbNpRQi"
   },
   "outputs": [],
   "source": [
    "# 모델 제거 후 성능 확인\n",
    "\n",
    "voting_clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-pDjW5XcHPOt"
   },
   "source": [
    "### **4. 다음 단계를 따라 앞에서 훈련시킨 분류 모델들을 이용하여 스태킹 앙상블을 구성해보자.**\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_xhEB_KtH47q"
   },
   "source": [
    "#### **STEP 1. 3번 문제의 각 분류 모델을 실행해서 검증 세트에서 예측을 만들고, 그 결과로 훈련 세트를 만들어 보세요.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3CLxYCROIAk6"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_test_pred = np.empty((len(X_test), len(models)), dtype=np.float32)\n",
    "for i, model in enumerate(models):\n",
    "    X_test_pred[:,i] = model.predict(X_test)\n",
    "X_test_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AHgSqi-zIBCd"
   },
   "source": [
    "####  **STEP 2. 새로운 훈련 세트를 이용하여 랜덤 포레스트 분류 모델을 학습시켜 보세요.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SsBT_d0MIH-V"
   },
   "outputs": [],
   "source": [
    "rnd_forest_blender = RandomForestClassifier(n_estimators=200,oob_score=True,random_state=42)\n",
    "rnd_forest_blender.fit(X_test_pred,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "43MJatnzquTH"
   },
   "source": [
    "- 이 랜덤 포레스트 분류 모델이 바로 블렌더에 해당합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zWozt0n2IJZL"
   },
   "source": [
    "####  **STEP 3. 이제 테스트셋에서 스태킹 앙상블 모델을 평가해보세요.**\n",
    "- 성능 평가 지표로 **정확도**를 이용하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yo4H-hTRIW7-"
   },
   "outputs": [],
   "source": [
    "# 각 분류 모델의 예측을 만들어 새로운 데이터셋 생성\n",
    "X_test_pred = np.empty((len(X_test), len(models)), dtype=np.float32)\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    X_test_pred[:,i] = model.predict(X_test)  # 각 리스트에서 i열만 뽑아내기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fVdwwmSYKDmF"
   },
   "outputs": [],
   "source": [
    "# 새로운 데이터셋을 이용하여 블렌더로 예측\n",
    "y_pred = rnd_forest_blender.predict(X_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ijlm1VbOKFSN"
   },
   "outputs": [],
   "source": [
    "# model test\n",
    "accuracy_score(y_test,y_pred)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
